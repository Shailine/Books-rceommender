{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive #mounting drive to read and write data to drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if running in Jupyter first we install scikit-surprise by going to anaconda comand prompt and typing the command below\n",
    "#conda install -c conda-forge scikit-surprise\n",
    "! pip install scikit-surprise\n",
    "import surprise\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "print(os.listdir(\"/content/drive/MyDrive/books\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=pd.read_csv('/content/drive/MyDrive/books/ratings.csv')\n",
    "raw.drop_duplicates(inplace=True)\n",
    "raw=raw.head(1000)\n",
    "print('we have',raw.shape[0], 'ratings')\n",
    "print('the number of unique users we have is:', len(raw.user_id.unique()))\n",
    "print('the number of unique books we have is:', len(raw.book_id.unique()))\n",
    "print(\"The median user rated %d books.\"%raw.user_id.value_counts().median())\n",
    "print('The max rating is: %d'%raw.rating.max(),\"the min rating is: %d\"%raw.rating.min())\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawTrain,rawholdout = train_test_split(ratings, test_size=0.25 )\n",
    "# when importing from a DF, you only need to specify the scale of the ratings.\n",
    "reader = surprise.Reader(rating_scale=(1,5)) \n",
    "#into surprise:\n",
    "data = surprise.Dataset.load_from_df(rawTrain,reader)\n",
    "holdout = surprise.Dataset.load_from_df(rawholdout,reader)\n",
    "holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kSplit = surprise.model_selection.split.KFold(n_splits=10, shuffle=True) # split data into folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = sim_options = {'name': 'cosine','user_based': False  # compute  similarities between items\n",
    "               } \n",
    "collabKNN = surprise.KNNBasic(k=40,sim_options=sim_options) #try removing sim_options. You'll find memory errors. \n",
    "rmseKNN = []\n",
    "rmseSVD = []\n",
    "rmseCo = []\n",
    "rmseSlope = []\n",
    "for trainset, testset in kSplit.split(data): #iterate through the folds.\n",
    "    collabKNN.fit(trainset)\n",
    "    predictionsKNN = collabKNN.test(testset)\n",
    "    rmseKNN.append(surprise.accuracy.rmse(predictionsKNN,verbose=True))#get root means squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funkSVD = surprise.prediction_algorithms.matrix_factorization.SVD(n_factors=30,n_epochs=10,biased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_error = 1\n",
    "for trainset, testset in kSplit.split(data): #iterate through the folds.\n",
    "    funkSVD.fit(trainset)\n",
    "    predictionsSVD = funkSVD.test(testset)\n",
    "    rmseSVD.append(surprise.accuracy.rmse(predictionsSVD,verbose=True))#get root means squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coClus = surprise.prediction_algorithms.co_clustering.CoClustering(n_cltr_u=4,n_cltr_i=4,n_epochs=25) \n",
    "for trainset, testset in kSplit.split(data): #iterate through the folds.\n",
    "    coClus.fit(trainset)\n",
    "    predictionsCoClus = coClus.test(testset)\n",
    "    rmseCo.append(surprise.accuracy.rmse(predictionsCoClus,verbose=True))#get root means squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopeOne = surprise.prediction_algorithms.slope_one.SlopeOne()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trainset, testset in kSplit.split(data): #iterate through the folds.\n",
    "    slopeOne.fit(trainset)\n",
    "    predictionsSlope = slopeOne.test(testset)\n",
    "    rmseSlope.append(surprise.accuracy.rmse(predictionsSlope,verbose=True))#get root means squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import AlgoBase\n",
    "\n",
    "class HybridModel(AlgoBase):\n",
    "\n",
    "    def __init__(self, models, weights, sim_options={}):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        \n",
    "        for model in self.models:\n",
    "            model.fit(trainset)\n",
    "                \n",
    "        return self\n",
    "\n",
    "    def estimate(self, user_id, item_id):\n",
    "        \n",
    "        scores_sum = 0\n",
    "        weights_sum = 0\n",
    "        \n",
    "        for i in range(len(self.models)):\n",
    "            scores_sum += self.models[i].estimate(user_id, item_id) * self.weights[i] # 3*1/4+4*3/4 laga ra\n",
    "            weights_sum += self.weights[i] # always becomes one\n",
    "            \n",
    "        return scores_sum / weights_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridFacto(surprise.AlgoBase):\n",
    "    def __init__(self,epochs, learning_rate,num_models):\n",
    "        self.alpha = np.array([1/len(num_models)]*len(num_models))\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "    def fit(self,holdout):\n",
    "        holdout=holdout.build_full_trainset().build_testset()\n",
    "        for epoch in range(self.epochs):\n",
    "          predictions = np.array([collabKNN.test(holdout),funkSVD.test(holdout),coClus.test(holdout),slopeOne.test(holdout)])\n",
    "          maeGradient = [surprise.accuracy.mae(prediction) for prediction in predictions]\n",
    "          newalpha = self.alpha - learning_rate * maeGradient  \n",
    "            #convergence check:\n",
    "          if newalpha - self.alpha < 0.001:\n",
    "                break\n",
    "          self.alpha = newalpha\n",
    "    def estimate(self,u,i): \n",
    "          if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible('User and/or item is unkown.')\n",
    "            algoResults = np.array([collabKNN.predict(u,i),funkSVD.predict(u,i),coClus.predict(u,i),slopeOne.predict(u,i)])\n",
    "            return np.sum(np.dot(self.alpha,algoResults))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = HybridFacto(10,0.05,4)\n",
    "hybrid.fit(holdout)\n",
    "rmseHyb = []\n",
    "for trainset, testset in kSplit.split(data): #iterate through the folds.\n",
    "    predhybrid = hybrid.test(testset)\n",
    "    rmseHyb.append(surprise.accuracy.rmse(predhybrid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
